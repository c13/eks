# Default values for kube-prometheus-stack.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

## Provide a name in place of kube-prometheus-stack for `app:` labels
##
nameOverride: ""

## Override the deployment namespace
##
namespaceOverride: ""

global:
  rbac:
    create: true

    ## Create ClusterRoles that extend the existing view, edit and admin ClusterRoles to interact with prometheus-operator CRDs
    ## Ref: https://kubernetes.io/docs/reference/access-authn-authz/rbac/#aggregated-clusterroles
    createAggregateClusterRoles: true

## Configuration for alertmanager
## ref: https://prometheus.io/docs/alerting/alertmanager/
##
alertmanager:
  templateFiles:  
    template_1.tmpl: |-  
        {{ define "slack.zetarin.text" }}
        {{- $root := . -}}
        {{ range .Alerts }}
          *Description:* {{ .Annotations.description }}
          *Environment:* {{ .Labels.env }}
          *Severity:* {{ .Labels.severity }}
          *Graph:* <{{ .GeneratorURL }}|:chart_with_upwards_trend:>
          *Runbook:* <{{ .Annotations.runbook }}|:spiral_note_pad:>
          *Details:*
            {{ range .Labels.SortedPairs }} - *{{ .Name }}:* `{{ .Value }}`
            {{ end }}
        {{ end }}
        {{ end }}

  ## Deploy alertmanager
  ##
  enabled: true

  ## Alertmanager configuration directives
  ## ref: https://prometheus.io/docs/alerting/configuration/#configuration-file
  ##      https://prometheus.io/webtools/alerting/routing-tree-editor/
  ##
  config:
    global:
      slack_api_url: https://hooks.slack.com/services/
    route:
      routes:
      - receiver: 'null'
        matchers:
          - alertname =~ "InfoInhibitor|Watchdog"
      - receiver: 'null'
        matchers:
          - namespace =~ "testing"
      - receiver: 'slack-alerts'
        matchers:
          - env = "zetarin"
      - receiver: 'slack-alerts'
    receivers:
    - name: 'null'
    - name: 'slack-alerts'
      slack_configs:
      - channel: '#alerts'
        send_resolved: true
        title: "{{ .CommonAnnotations.summary }}"
        text: '{{ template "slack.zetarin.text" . }}'
    - name: 'slack-infrastructure-alerts'
      slack_configs:
      - channel: '#infra-alerts'
        send_resolved: true
    templates:
    - '/etc/alertmanager/config/*.tmpl'

  ingress:
    enabled: false

    # For Kubernetes >= 1.18 you should specify the ingress-controller via the field ingressClassName
    # See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#specifying-the-class-of-an-ingress
    ingressClassName: nginx

    ## Redirect ingress to an additional defined port on the service
    # servicePort: 8081

    ## Hosts must be provided if Ingress is enabled.
    ##
    hosts:
      - alertmanager-rc.zetarin.org

    ## Paths to use for ingress rules - one path should match the alertmanagerSpec.routePrefix
    ##
    paths:
      - /

    ## For Kubernetes >= 1.18 you should specify the pathType (determines how Ingress paths should be matched)
    ## See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#better-path-matching-with-path-types
    pathType: ImplementationSpecific

    ## TLS configuration for Alertmanager Ingress
    ## Secret must be manually created in the namespace
    ##
    tls: []
    # - secretName: alertmanager-general-tls
    #   hosts:
    #   - alertmanager.example.com

  ## Settings affecting alertmanagerSpec
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#alertmanagerspec
  ##
  alertmanagerSpec:
    ## Namespaces to be selected for AlertmanagerConfig discovery. If nil, only check own namespace.
    ##
    alertmanagerConfigNamespaceSelector:
      matchLabels:
        alertmanagerconfig: enabled

    ## Size is the expected size of the alertmanager cluster. The controller will eventually make the size of the
    ## running cluster equal to the expected size.
    replicas: 3

    nodeSelector: {}
      # node.zetarin.org/role: "infrastructure"

    ## If specified, the pod's tolerations.
    ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
    ##
    tolerations: []
    # - key: "node.zetarin.org/role"
    #   operator: "Equal"
    #   value: "infrastructure"
    #   effect: "NoSchedule"

    # - key: "key"
    #   operator: "Equal"
    #   value: "value"
    #   effect: "NoSchedule"

## Using default values from https://github.com/grafana/helm-charts/blob/main/charts/grafana/values.yaml
##
grafana:
  enabled: true
  assertNoLeakedSecrets: false
  adminPassword: FHkjgdfs2342lk

  rbac:
    create: true
    ## If true, Grafana PSPs will be created
    ##
    pspEnabled: false

  ingress:
    ## If true, Grafana Ingress will be created
    ##
    enabled: true

    ## IngressClassName for Grafana Ingress.
    ## Should be provided if Ingress is enable.
    ##
    ingressClassName: nginx

    ## Hostnames.
    ## Must be provided if Ingress is enable.
    ##
    # hosts:
    #   - grafana.domain.com
    hosts:
      - grafana-rc.zetarin.org

    ## Path for grafana ingress
    path: /

    ## TLS configuration for grafana Ingress
    ## Secret must be manually created in the namespace
    ##
    tls: []
    # - secretName: grafana-general-tls
    #   hosts:
    #   - grafana.example.com

  sidecar:
    dashboards:
      provider:
        allowUiUpdates: false
      searchNamespace: ALL

  ### Google OAuth
  grafana.ini:
    server:
      root_url: "https://grafana-rc.zetarin.org/"
    users:
      auto_assign_org_id: 1
      #home_page: "/"
      #viewers_can_edit: "true"

  persistence:
    type: pvc
    enabled: true

## Component scraping the kube api server
##
kubeApiServer:
  enabled: true

## Component scraping the kubelet and kubelet-hosted cAdvisor
##
kubelet:
  enabled: true

## Component scraping the kube controller manager
##
kubeControllerManager:
  enabled: false

## Component scraping coreDns. Use either this or kubeDns
##
coreDns:
  enabled: false

## Component scraping kubeDns. Use either this or coreDns
##
kubeDns:
  enabled: true

## Component scraping etcd
##
kubeEtcd:
  enabled: false

## Component scraping kube scheduler
##
kubeScheduler:
  enabled: false

## Component scraping kube proxy
##
kubeProxy:
  enabled: false

## Component scraping kube state metrics
##
kubeStateMetrics:
  enabled: true

## Configuration for kube-state-metrics subchart
##
kube-state-metrics:
  rbac:
    create: true

## Deploy node exporter as a daemonset to all nodes
##
nodeExporter:
  enabled: true

## Manages Prometheus and Alertmanager components
##
prometheusOperator:
  enabled: true

  ## Admission webhook support for PrometheusRules resources added in Prometheus Operator 0.30 can be enabled to prevent incorrectly formatted
  ## rules from making their way into prometheus and potentially preventing the container from starting
  admissionWebhooks:
    patch:
      enabled: true
      nodeSelector: {}
        # node.zetarin.org/role: "infrastructure"
      tolerations: []
      # - key: "node.zetarin.org/role"
      #   operator: "Equal"
      #   value: "infrastructure"
      #   effect: "NoSchedule"

  ## Define which Nodes the Pods are scheduled on.
  ## ref: https://kubernetes.io/docs/user-guide/node-selection/
  ##
  nodeSelector: {}
    # node.zetarin.org/role: "infrastructure"

  ## Tolerations for use with node taints
  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  ##
  tolerations: []
  # - key: "node.zetarin.org/role"
  #   operator: "Equal"
  #   value: "infrastructure"
  #   effect: "NoSchedule"


## Deploy a Prometheus instance
##
prometheus:
  enabled: true

  ingress:
    enabled: false

    # For Kubernetes >= 1.18 you should specify the ingress-controller via the field ingressClassName
    # See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#specifying-the-class-of-an-ingress
    ingressClassName: nginx

    hosts:
      - prometheus-rc.zetarin.org

    ## For Kubernetes >= 1.18 you should specify the pathType (determines how Ingress paths should be matched)
    ## See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#better-path-matching-with-path-types
    # pathType: ImplementationSpecific
    pathType: Prefix

    ## TLS configuration for Prometheus Ingress
    ## Secret must be manually created in the namespace
    ##
    tls: []
      # - secretName: prometheus-general-tls
      #   hosts:
      #     - prometheus.example.com

  ## Settings affecting prometheusSpec
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#prometheusspec
  ##
  prometheusSpec:
    ## Tolerations for use with node taints
    ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
    ##
    tolerations: []
    # - key: "node.zetarin.org/role"
    #   operator: "Equal"
    #   value: "infrastructure"
    #   effect: "NoSchedule"

    ## Define which Nodes the Pods are scheduled on.
    ## ref: https://kubernetes.io/docs/user-guide/node-selection/
    ##
    nodeSelector: {}
      # node.zetarin.org/role: "infrastructure"


    ## If true, a nil or {} value for prometheus.prometheusSpec.serviceMonitorSelector will cause the
    ## prometheus resource to be created with selectors based on values in the helm deployment,
    ## which will also match the servicemonitors created
    ##
    serviceMonitorSelectorNilUsesHelmValues: false

    ## Namespaces to be selected for ServiceMonitor discovery.
    ##
    serviceMonitorNamespaceSelector: {}
      # matchLabels:
      #   prometheusMonitoring: "true"
    ruleSelectorNilUsesHelmValues: false
    ruleSelector: {}

    ## Number of replicas of each shard to deploy for a Prometheus deployment.
    ## Number of replicas multiplied by shards is the total number of Pods created.
    ##
    replicas: 1
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: standard-rwo
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 20Gi

## Configuration for thanosRuler
## ref: https://thanos.io/tip/components/rule.md/
##
thanosRuler:

  ## Deploy thanosRuler
  ##
  enabled: false
